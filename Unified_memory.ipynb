{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhcKH/4RRcm60KUNg5q/+w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-pandey5/CUDA/blob/main/Unified_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unified memory use  cudaMallocManaged() where we don't have to use Memcpy for device and host seprately. The one thing to remember with unified memory is that you still need cudaDeviceSynchronize() after kernel launches to ensure all GPU operations are complete before accessing the data on the CPU side"
      ],
      "metadata": {
        "id": "ij6GZNSC-R5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qCOcOIITJzS",
        "outputId": "8e5b0dca-9e6e-494a-802c-d97479e2b937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting unified.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile unified.cu\n",
        "#include <stdio.h>\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "using std::cout;\n",
        "//CUDA kernel for vector addition\n",
        "__global__ void vectorAdd(int*a , int *b, int*c , int N){\n",
        "  // global thread include\n",
        "  int tid = (blockDim.x*blockIdx.x)+ threadIdx.x;\n",
        "  //Boundary check\n",
        "  if (tid<N){\n",
        "    c[tid]= a[tid] + b[tid];\n",
        "  }\n",
        "\n",
        "}\n",
        "int main(){\n",
        "  const int N = 1<<16;\n",
        "  size_t bytes = N* sizeof(int);\n",
        "  //unified memory pointers\n",
        "  int *a , *b , *c;\n",
        "  // Allocation memory for these pointers\n",
        "  cudaMallocManaged(&a, bytes);\n",
        "  cudaMallocManaged(&b , bytes);\n",
        "  cudaMallocManaged(&c, bytes);\n",
        "  // intialise the vector\n",
        "  for (int i =0; i<N; i++){\n",
        "    a[i]= rand()% 100;\n",
        "    b[i]= rand()% 100;  }\n",
        "    // 1024 threads per block\n",
        "    int block_size= 1<<10;\n",
        "    // no. of block per grid\n",
        "    int grid_size = (N+block_size-1)/ block_size;\n",
        "    vectorAdd<<<grid_size,block_size>>>(a,b,c,N);\n",
        "    // as there is no memcpy so we have to synchronise the thread\n",
        "    cudaDeviceSynchronize();\n",
        "    // Print a few elements from each array with printf\n",
        "printf(\"First 5 elements of arrays:\\n\");\n",
        "for (int i = 0; i < 5; i++) {\n",
        "    printf(\"a[%d] = %d, b[%d] = %d, c[%d] = %d\\n\", i, a[i], i, b[i], i, c[i]);\n",
        "}\n",
        "\n",
        "printf(\"Last 5 elements of arrays:\\n\");\n",
        "for (int i = N - 5; i < N; i++) {\n",
        "    printf(\"a[%d] = %d, b[%d] = %d, c[%d] = %d\\n\", i, a[i], i, b[i], i, c[i]);\n",
        "}\n",
        "    // verify the result on the CPU\n",
        "    for (int i =0; i<N; i++){\n",
        "      assert (c[i]==a[i]+b[i]);\n",
        "    }\n",
        "    //free the unified memory\n",
        "    cudaFree(a);\n",
        "    cudaFree(b);\n",
        "    cudaFree(c);\n",
        "    cout<<\"Completed successfully\";\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc unified.cu -o unified"
      ],
      "metadata": {
        "id": "SZsrSPfd3nRL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 unified.cu -o unified"
      ],
      "metadata": {
        "id": "UPyNFetY316E"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./unified"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ror0MSEC353E",
        "outputId": "be7bf2ae-c3ea-4055-ae23-5dff1bfe0998"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 elements of arrays:\n",
            "a[0] = 83, b[0] = 86, c[0] = 169\n",
            "a[1] = 77, b[1] = 15, c[1] = 92\n",
            "a[2] = 93, b[2] = 35, c[2] = 128\n",
            "a[3] = 86, b[3] = 92, c[3] = 178\n",
            "a[4] = 49, b[4] = 21, c[4] = 70\n",
            "Last 5 elements of arrays:\n",
            "a[65531] = 45, b[65531] = 67, c[65531] = 112\n",
            "a[65532] = 21, b[65532] = 68, c[65532] = 89\n",
            "a[65533] = 98, b[65533] = 20, c[65533] = 118\n",
            "a[65534] = 86, b[65534] = 62, c[65534] = 148\n",
            "a[65535] = 18, b[65535] = 67, c[65535] = 85\n",
            "Completed successfully"
          ]
        }
      ]
    }
  ]
}